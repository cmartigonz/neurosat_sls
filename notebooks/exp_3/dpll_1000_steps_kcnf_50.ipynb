{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-17 17:59:53.807934: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-07-17 17:59:53.867398: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:\n",
      "2024-07-17 17:59:53.867418: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1850] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2024-07-17 17:59:53.868259: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "export_dir = \"export_sr_50/1721309719\"\n",
    "loaded_model = tf.saved_model.load(export_dir)\n",
    "predict_fn = loaded_model.signatures['serving_default']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "sys.path.insert(0,'..')\n",
    "sys.path.insert(0,'../..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from cnf_dataset import clauses_to_matrix\n",
    "from dpll import DPLL, RandomClauseDPLL, MostCommonVarDPLL, RandomVarDPLL\n",
    "from cnf import get_random_kcnf, CNF, get_sats_SR, get_pos_SR, get_random_kcnfs\n",
    "from tqdm import tqdm\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from collections import defaultdict\n",
    "\n",
    "def jw(clauses):\n",
    "    score = defaultdict(int)\n",
    "\n",
    "    for clause in clauses:\n",
    "        for l in clause:\n",
    "            score[l] += 2. ** (-len(clause))\n",
    "\n",
    "    return max(score, key=score.get)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "LIMIT_RUNS = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shorten_cnf(cnf: CNF):\n",
    "    for c in cnf.clauses:\n",
    "        if len(c) == 1:\n",
    "            # print(\"Chosen lone clause\", c[0])\n",
    "            return shorten_cnf(cnf.set_var(c[0]))\n",
    "    all_literals = set(x\n",
    "                       for clause in cnf.clauses\n",
    "                       for x in clause)\n",
    "    for v in cnf.vars:\n",
    "        if v in all_literals and (-v) not in all_literals:\n",
    "            # print(\"Chosen lone literal\", v)\n",
    "            return shorten_cnf(cnf.set_var(v))\n",
    "        if (-v) in all_literals and v not in all_literals:\n",
    "            # print(\"Chosen lone literal\", -v)\n",
    "            return shorten_cnf(cnf.set_var(-v))\n",
    "    return cnf\n",
    "\n",
    "def make_normalized(cls):\n",
    "    class NormalizedDPLL(cls):\n",
    "        def run(self, cnf: CNF):\n",
    "            assert isinstance(cnf, CNF)\n",
    "            self.number_of_runs += 1\n",
    "            if self.number_of_runs > LIMIT_RUNS:\n",
    "                return None\n",
    "            \n",
    "            cnf = shorten_cnf(cnf)\n",
    "            if cnf.is_true():\n",
    "                return []\n",
    "            elif cnf.is_false():\n",
    "                return None\n",
    "\n",
    "            sug_var = self.suggest(cnf)\n",
    "            sug_cnf = cnf.set_var(sug_var)\n",
    "\n",
    "            sug_res = self.run(sug_cnf)\n",
    "            if sug_res is not None:\n",
    "                return [sug_var] + sug_res\n",
    "\n",
    "            not_sug_cnf = cnf.set_var(-sug_var)\n",
    "            not_sug_res = self.run(not_sug_cnf)\n",
    "            if not_sug_res is not None:\n",
    "                self.number_of_errors += 1\n",
    "                return [-sug_var] + not_sug_res\n",
    "            return None\n",
    "    NormalizedDPLL.__name__ = \"Normalized{}\".format(cls.__name__)\n",
    "    return NormalizedDPLL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(precision=3, suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "BATCH_SIZE = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Because we have to pass full batch\n",
    "\n",
    "class GraphBasedDPLL(DPLL):\n",
    "    def suggest(self, input_cnf: CNF):\n",
    "        clause_num = len(input_cnf.clauses)\n",
    "        var_num = max(input_cnf.vars)\n",
    "        inputs = np.asarray([clauses_to_matrix(input_cnf.clauses, clause_num, var_num)] * BATCH_SIZE, dtype=np.float32)\n",
    "        \n",
    "        inputs_tensor = tf.convert_to_tensor(inputs)\n",
    "\n",
    "        # Hacer la predicción usando la firma\n",
    "        predictions = predict_fn(input=inputs_tensor)\n",
    "\n",
    "        # Extraer las probabilidades de política\n",
    "        policy_probs = predictions['policy_probabilities'].numpy()\n",
    "        \n",
    "        best_prob = 0.0\n",
    "        best_svar = None\n",
    "        for var in input_cnf.vars:\n",
    "            for svar in [var, -var]:\n",
    "                svar_prob = policy_probs[0][var-1][0 if svar > 0 else 1]\n",
    "                if svar_prob > best_prob:\n",
    "                    best_prob = svar_prob\n",
    "                    best_svar = svar\n",
    "        return best_svar\n",
    "\n",
    "class MostCommonDPLL(DPLL):\n",
    "    def suggest(self, cnf: CNF):\n",
    "        counter = Counter()\n",
    "        for clause in cnf.clauses:\n",
    "            for svar in clause:\n",
    "                counter[svar] += 1\n",
    "        return counter.most_common(1)[0][0]\n",
    "    \n",
    "class JeroslawDPLL(DPLL):\n",
    "    def suggest(self, cnf: CNF):\n",
    "        return jw(cnf.clauses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "NormalizedGraphBasedDPLL = make_normalized(GraphBasedDPLL)\n",
    "NormalizedMostCommonDPLL = make_normalized(MostCommonDPLL)\n",
    "NormalizedJeroslawDPLL = make_normalized(JeroslawDPLL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_steps(sats, dpll_cls):\n",
    "    steps = []\n",
    "    errors = []\n",
    "    solved = 0\n",
    "    for sat in tqdm(sats):\n",
    "        dpll = dpll_cls()\n",
    "        res = dpll.run(sat)\n",
    "        if res is not None:\n",
    "            steps.append(dpll.number_of_runs)\n",
    "            errors.append(dpll.number_of_errors)\n",
    "            solved += 1\n",
    "    print(\"Within {} steps solved {} problems out of {}\".format(LIMIT_RUNS, solved, len(sats)))\n",
    "    return steps, errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_and_print_steps(sats, dpll_cls):\n",
    "    steps, errors = compute_steps(sats, dpll_cls)\n",
    "    print(\"#Sats: {}; avg step: {:.2f}; stdev step: {:.2f}; avg error: {:.2f}; stdev error: {:.2f}\".format(\n",
    "        len(steps), np.mean(steps), np.std(steps), np.mean(errors), np.std(errors)))\n",
    "    plt.figure(figsize=(14, 4))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.title(\"Steps of {}\".format(dpll_cls.__name__))\n",
    "    plt.hist(steps, bins=20) # range(2**(N+1)))\n",
    "    plt.ylim((0, len(sats)))\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.title(\"Errors of {}\".format(dpll_cls.__name__))\n",
    "    plt.hist(errors, bins=range(N+1))\n",
    "    plt.ylim((0, len(sats)))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# s - number of samples\n",
    "# n - max number of clauses, use 100 * m\n",
    "# m - number of variables\n",
    "\n",
    "def print_all(s, n, m, light=False):\n",
    "    global S, N, M\n",
    "    S = s\n",
    "    N = n # number of clauses\n",
    "    M = m # number of variables\n",
    "    \n",
    "    MAX_TRIES = 100000\n",
    "    sats = []\n",
    "    \n",
    "    random.seed(1)\n",
    "    np.random.seed(1)\n",
    "    \n",
    "    for index in range(MAX_TRIES):\n",
    "        if len(sats) >= S:\n",
    "            break\n",
    "        #sat = get_pos_SR(M, M, N)\n",
    "        sat = get_random_kcnf(3,N, M)\n",
    "        sats.append(sat)\n",
    "    assert len(sats) == S\n",
    "    \n",
    "    print(\"We have generated {} formulas\".format(len(sats)))\n",
    "    compute_and_print_steps(sats, NormalizedGraphBasedDPLL)\n",
    "    compute_and_print_steps(sats, NormalizedMostCommonDPLL)\n",
    "    compute_and_print_steps(sats, NormalizedJeroslawDPLL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_all(100, 20, 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print_all(100, 40, 120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_all(100, 50, 150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_all(100, 70, 210)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print_all(100, 90, 270)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_all(100, 110, 330)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
